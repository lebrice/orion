{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'orion.benchmark.warm_start_study'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-bd6ecf9e2716>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0morion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbenchmark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRosenBrock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEggHolder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCarromTable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0morion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbenchmark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarm_start_study\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWarmStartStudy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0morion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbenchmark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massessment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarm_start_efficiency\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWarmStartEfficiency\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0morion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbenchmark\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBenchmark\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'orion.benchmark.warm_start_study'"
     ]
    }
   ],
   "source": [
    "from orion.benchmark.benchmark_client import get_or_create_benchmark\n",
    "\n",
    "from orion.benchmark.assessment import AverageResult, AverageRank\n",
    "\n",
    "from orion.benchmark.task import RosenBrock, EggHolder, CarromTable\n",
    "from orion.benchmark.warm_start_study import WarmStartStudy\n",
    "from orion.benchmark.assessment.warm_start_efficiency import WarmStartEfficiency\n",
    "from orion.benchmark import Benchmark\n",
    "from orion.benchmark.warm_start_benchmark import WarmStartBenchmark\n",
    "\n",
    "from warmstart.new_knowledge_base import KnowledgeBase\n",
    "from warmstart.tasks.quadratics import QuadraticsTask\n",
    "from warmstart.tasks.profet import SvmTask\n",
    "from ablr.ablr import ABLR\n",
    "import numpy as np\n",
    "from typing import List\n",
    "# TODO: Need to make sure that in the \"hot_start\" case, all points have the same\n",
    "# task id? Or maybe use the branching could be used?\n",
    "from orion.benchmark.task.utils importsimilarity, distance\n",
    "\n",
    "# print(distance(task_a, task_b))\n",
    "# print(similarity(task_a, task_b))\n",
    "\n",
    "# print(task_a, task_b)\n",
    "# exit()\n",
    "target_task = QuadraticsTask(a0=0.1, a1=0.1, a2=0.1, task_id=0, max_trials=25)\n",
    "N = 4\n",
    "\n",
    "# BUG: Figure out why we observe '50' warm-start points, rather than 25.\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "benchmark = WarmStartBenchmark(\n",
    "    name=\"warmstart_benchmark\",\n",
    "    algorithms=[\n",
    "        # \"random\",\n",
    "        \"tpe\",\n",
    "        # \"ablr\",\n",
    "        # ABLR,\n",
    "        # \"BayesianOptimizer\", # Doesn't work!\n",
    "    ],\n",
    "    source_tasks = [\n",
    "        target_task.get_similar_task(i * (1 / N), task_id=i, max_trials=25)\n",
    "        for i in range(N+1)\n",
    "    ],\n",
    "    target_tasks = [\n",
    "        target_task for _ in range(N+1)\n",
    "    ],\n",
    "    repetitions = 5,\n",
    "    knowledge_base_type=KnowledgeBase,\n",
    "    debug=True,\n",
    ")\n",
    "\n",
    "benchmark.process()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "status = benchmark.status(False)\n",
    "figures = benchmark.analysis()\n",
    "for figure in figures:\n",
    "    figure.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python388jvsc74a57bd02c8858e014650328496d8290b6c5ec443cc2d082b4089dd43822f8f34fcc52d1",
   "display_name": "Python 3.8.8 64-bit ('warm-start': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "2c8858e014650328496d8290b6c5ec443cc2d082b4089dd43822f8f34fcc52d1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}